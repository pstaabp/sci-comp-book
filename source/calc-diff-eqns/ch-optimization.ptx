<?xml version="1.0" encoding="UTF-8"?>

<chapter xml:id="ch-optimization">
  <title>Optimization</title>

  <introduction>
    <p>
      Optimization is an extremely useful subject in Scientific Computation and is often used in other fields.  In short, optimization is the selection of some parameters in order to minimization or maximize some function.  A simple example is if we have a function like <m>f(x) = x^2</m> which has the plot:
    </p>

    <figure xml:id="fig-opt-xsq">
      <caption></caption>
      <image source="plots/optimization/xsq.png">
        <shortdescription>
          (for accessibility)
        </shortdescription>
      </image>
    </figure>

    <p>
      and we are trying to find the minimum of the function, which appears to be an <m>x=1</m> from the plot.
    </p>

    <p>
      Recall the following definitions of optimal points:
    </p>

    <definition xml:id="def-local-opt-var">
      <statement>
        <p>
          Consider a function <m>f(x)</m> that is continuous on some open interval containing <m>c</m>.
        </p>

        <p>
          <ul>
            <li>
              <p>
                a <term>local minimum</term> is a number <m>f(c)</m>, such that <m>f(x)\geq f(c)</m> for all <m>x</m> in the interval <m>[c-\epsilon,c+\epsilon]</m> for some small <m>\epsilon &gt; 0</m>.
              </p>
            </li>

            <li>
              <p>
                a <term>local maximum</term> is a number <m>f(c)</m>, such that <m>f(x)\geq f(c)</m> for all <m>x</m> in the interval <m>[c-\epsilon,c+\epsilon]</m> for some small <m>\epsilon &gt; 0</m>.
              </p>
            </li>
          </ul>
        </p>
      </statement>
    </definition>

    <p>
      We can extend this to functions of more that one variable.  The following is the definition of optimal points of functions of two variables and further can be found in [REF??]
    </p>

    <definition xml:id="def-local-rn">
      <statement>
        <p>
          Consider a function <m>f(x,y)</m> that is continuous on some open ball of radius <m>\epsilon  &gt; 0</m>  containing the point <m>(x_0,y_0)</m>, denoted <m>B_{(x_0,y_0)}(\epsilon)</m>
        </p>

        <p>
          <ul>
            <li>
              <p>
                a <term>local minimum</term> is a number <m>f(x_0,y_0)</m>, such that <m>f(x,y)\geq f(x_0,y_0)</m> for all <m>x</m> in the ball <m>B_{(x_0,y_0)}(\epsilon)</m>
              </p>
            </li>

            <li>
              <p>
                a <term>local minimum</term> is a number <m>f(x_0,y_0)</m>, such that <m>f(x,y)\leq f(x_0,y_0)</m> for all <m>x</m> in the ball <m>B_{(x_0,y_0)}(\epsilon)</m>
              </p>
            </li>
          </ul>
        </p>
      </statement>
    </definition>
  </introduction>

  <section>
    <title>Newton's Method</title>

    <p>
      We saw Newton's Method in <xref ref="ch-rootfinding"/> which found values where <m>f(x)=0</m>.  If a function is differentiable, then we can use Newton's Method on <m>f'(x)</m> to find minima and maxima.
    </p>

    <p>
      First, make sure that you have the <c>Rootfinding.jl</c> file and then
    </p>

    <p>
      <cd>
      <cline>include("Rootfinding.jl")</cline>
      <cline>using ForwardDiff, .Rootfinding, LinearAlgebra</cline>
      </cd>
    </p>

    <p>
      Then we can use Newton's method on the derivative of the function
    </p>

    <p>
      <cd>
      <cline>f(x::Real) = (x-1)^2</cline>
      </cd>
    </p>

    <p>
      by
    </p>

    <p>
      <cd>
      <cline>newton(x -&gt; ForwardDiff.derivative(f,x),0)</cline>
      </cd>
    </p>

    <p>
      which returns
    </p>

    <p>
      <cd>
      <cline>The root is approximately x̂ = 1.0</cline>
      <cline>An estimate for the error is 0.0</cline>
      <cline>with f(x̂) = 0.0</cline>
      <cline>which took 1 steps</cline>
      </cd>
    </p>

    <p>
      This method works reasonably well to find local minima or maxima of functions of 1 variable if the function is differentiable.  However, often, functions are of more than one variable and not differentiable and we would still like to find optimum points. There are other more robust methods that we start with below.
    </p>
  </section>

  <section>
    <title>Gradient Descent</title>

    <introduction>
      <p>
        The basic method for optimizing functions of more than 1 variable is called gradient descent.  Consider
      </p>

      <p>
        <men xml:id="eq-f">
          f(x,y) = \sin\biggl(\frac{1}{2}x^2-\frac{1}{4}y^2+2\biggr)\cos(x+y)
        </men>
      </p>

      <p>
        we can produce a contour plot of the region <m>[0,\pi]\times[0,\pi]</m> with
      </p>

      <p>
        <cd>
        <cline>x = y = LinRange(0,pi,101)</cline>
        <cline>contour(x, y, (x, y) -&gt; sin(0.5x^2-0.25y^2+2)*cos(x+y)) </cline>
        </cd>
      </p>

      <p>
        and these commands results in the following contour plot.
      </p>

      <figure xml:id="fig-contour">
        <caption></caption>
        <image source="plots/optimization/contour.png">
          <shortdescription>
            (for accessibility)
          </shortdescription>
        </image>
      </figure>

      <p>
        The colors of the contours have heights given on the bar to the side.  There is a local minimum near the point <m>(1,2)</m> and we will use a gradient descent method to find this.
      </p>

      <p>
        The idea with gradient descent is that a starting point is chosen in a manner similar to that of Newton's method.  The gradient of a function, <m>\nabla f</m>, denotes a vector showing the direction of greatest increase.  Since we are seeking a minimum, the direction of greatest descent is the opposite direction or <m>-\nabla f</m>.
      </p>

      <p>
        <me>
          \mathbf{x}_{n+1} = \mathbf{x}_n - \gamma_n \nabla f(\mathbf{x}_n)
        </me>
      </p>

      <p>
        where <m>\gamma_n</m> is some number that may depend on the point.
      </p>
    </introduction>


    <subsection>
      <title>Gradient Descent using Julia</title>

      <p>
        Here is some julia code that will peform a simple gradient descent algorithm.
      </p>


      <program language="julia" line-numbers="yes">
        <input>
function gradientDescent(f::Function,x₀::Vector; γ = 0.25, max_steps = 100)
  local steps = 0
  local ∇f₀ = [1,1] # initialize it to get into while loop
  while norm(∇f₀) &gt; 1e-8 &amp;&amp; steps &lt; max_steps
    ∇f₀ = ForwardDiff.gradient(f,x₀)
    x₀ = x₀ - γ*∇f₀
    steps += 1
  end
  steps &lt; max_steps || throw(ErrorException("The number of steps has exceeded $max_steps"))
  x₀
end
        </input>
      </program>

      <p>
        and we can use this code<fn>To get the <m>\nabla</m> symbol above, type <c>\nabla</c>, then hit TAB. To get subscripts like <c>x₀</c>, type <c>x</c>then <c>\_0</c>then hit tab.  You can get other numerical subscripts with other digits after the underscore.</fn> to find a minimum of the function in <xref ref="eq-f"/>, first we define it as
      </p>

      <p>
        <cd>
        <cline> f(x::Vector) = sin(0.5x[1]^2-0.25x[2]^2+2)*cos(x[1]+x[2])</cline>
        </cd>
      </p>

      <p>
        where the value <c>x</c> needs to be a <c>Vector</c>, which is a 1D array, for the ease of taking gradients with the <c>ForwardDiff.gradient</c>function. The standard <m>x</m> and <m>y</m> variables are <c>x[1]</c>and <c>x[2]</c>respectively.  To find the minimum with this function use:
      </p>

      <p>
        <cd>
        <cline>gradientDescent(f,[0.1,0.1])</cline>
        </cd>
      </p>

      <p>
        which returns
      </p>

      <p>
        <cd>
        <cline>2-element Vector{Float64}:</cline>
        <cline>  1.1036863833552772</cline>
        <cline>  2.0379062674731965</cline>
        </cd>
      </p>

      <exercise>
        <p>
          The maximum can be found using this same method by finding the minimum of the negative of this function.  Find the maximum of this same function near the point <m>(2.5,0.5)</m>.
        </p>
      </exercise>
    </subsection>


    <subsection>
      <title>The Barzilai–Borwein method</title>

      <p>
        We used a constant for the value <m>\gamma</m> above, however, in [REF!!!], Barzilai and Borwein developed a steepest descent method that acts much like Newton's method in term of convergence speed by selecting:
      </p>

      <p>
        <me>
          \gamma_n = \frac{|(\mathbf{x}_n-\mathbf{x}_{n-1})^T(\nabla f(\mathbf{x}_n) - \nabla f(\mathbf{x}_{n-1}))|} {||\nabla f(\mathbf{x}_n) - \nabla f(\mathbf{x}_{n-1})||^2}
        </me>
      </p>

      <p>
        Note, though that <m>\gamma_n</m> requires knowing information at the previous step (both <m>\mathbf{x}_{n-1}</m> and <m>\nabla f(\mathbf{x}_{n-1})</m>) which is not available on the first step.  We can use the simple gradient descent (where we used a constant value of <m>\gamma</m>) on the first step and then
      </p>


      <program language="julia" line-numbers="yes">
        <input>
function gradientDescentBB(f::Function,x₀::Vector; max_steps = 100)
  local steps = 0
  local ∇f₀ = ForwardDiff.gradient(f,x₀)
  local x₁ = x₀ - 0.25 * ∇f₀
  while norm(∇f₀) &gt; 1e-4 &amp;&amp; steps &lt; max_steps
    ∇f₁ = ForwardDiff.gradient(f,x₁)
    Δ∇f = ∇f₁-∇f₀
    x₂ = x₁ - abs(dot(x₁-x₀,Δ∇f))/norm(Δ∇f)^2*∇f₁
    x₀ = x₁
    x₁ = x₂
    ∇f₀ = ∇f₁
    steps += 1
  end
  steps &lt; max_steps || throw(ErrorException("The number of steps has exceeded $max_steps"))
  x₁
end
        </input>
      </program>

      <p>
        Then
      </p>

      <p>
        <cd> gradientDescentBB(f,[0.1,0.1]) </cd>
      </p>

      <p>
        which returns
      </p>

      <p>
        <cd>
        <cline>2-element Vector{Float64}:</cline>
        <cline>  1.1036850670346863</cline>
        <cline>  2.0379038305805874</cline>
        </cd>
      </p>
    </subsection>
  </section>

  <section>
    <title>Fitting Data to a Line -- Linear Regression</title>

    <introduction>
      <p>
        We saw in <xref ref="ch-algorithm-analysis"/> of fitting various functions to data.  We skipped over a lot of details there by using a package called <c>LsqFit</c>.  We're going to revisit this by using the techniques here, which allows use to find fits in more generally ways than using that package.  We'll start with a common task of finding the best fit line through a set of points and let's just take a small example.  Let
      </p>

      <p>
        <cd> pts=[(1,8), (2,7), (4,6), (5,6),  (8,4) ,(9,2), (10,1)] </cd>
      </p>

      <p>
        and let's plot them with
      </p>

      <p>
        <cd> scatter(map(pt-&gt;pt[1],pts),map(pt-&gt;pt[2],pts),legend=false) </cd>
      </p>

      <p>
        which results in
      </p>

      <figure xml:id="fig-opt-scatter">
        <caption></caption>
        <image source="plots/optimization/scatter.png">
          <shortdescription>
            (for accessibility)
          </shortdescription>
        </image>
      </figure>

      <p>
        Let
        <me>
          E = \sum_{i=1}^N (mx_i+b -y_i)^2
        </me>
      </p>

      <p>
        and we want to minimize this recalling that the variables are <m>m</m> and <m>b</m> (note that <m>x</m> and <m>y</m> are the data).  Basically, this comes down to defining the function <m>E</m> in julia and using one of the methods from above. We can write <m>E</m> down like
      </p>

      <p>
        <cd>
        <cline>leastSqLine(coeffs::Vector{T}) where T &lt;: Real = sum(pt -&gt; (coeffs[1]*pt[1]+coeffs[2]-pt[2])^2,pts)</cline>
        </cd>
      </p>

      <p>
        where <c>pts</c>is defined above.  If we try
      </p>

      <p>
        <cd>
        <cline>gradientDescent(leastSqLine,[-1,10])</cline>
        </cd>
      </p>

      <p>
        the result is <c>The number of steps has exceeded 100.</c> Oops.  This is common for some functions of more that one variable.  If we look at a contour plot with the command:
      </p>

      <p>
        <cd>
        <cline>x = LinRange(-5,5,201)</cline>
        <cline>y = LinRange(5,15,201) </cline>
        <cline>contour(x,y,(x,y) -&gt; leastSqLine([x,y]),levels=[0,10,20,50,100,200,500,1000,2000])</cline>
        </cd>
      </p>

      <figure xml:id="fig-opt-contour2">
        <caption></caption>
        <image source="plots/optimization/contour2.png">
          <shortdescription>
            (for accessibility)
          </shortdescription>
        </image>
      </figure>

      <p>
        you can see that there appears to be a minimum, however it is in a long narrow canyon.  This is a common example where gradient descent does not work well, even if we try different values of <m>\gamma</m>. (Try it!!) Instead, if we use the  Barzilai–Borwein method,
      </p>

      <p>
        <cd>
        <cline>opt = gradientDescentBB(leastSqLine,[-1,10])</cline>
        </cd>
      </p>

      <p>
        results in
      </p>

      <p>
        <cd>
        <cline>2-element Vector{Float64}:</cline>
        <cline>  -0.7248062015540494</cline>
        <cline>   8.89534883720881</cline>
        </cd>
      </p>

      <p>
        and this is the same as <m>m</m> = -0.7248062015540494 and <m>b</m>= 8.89534883720881.
      </p>

      <p>
        Plotting the data above, with the least-square line with:
      </p>

      <p>
        <cd>
        <cline>scatter(map(pt-&gt;pt[1],pts),map(pt-&gt;pt[2],pts),legend=false) </cline>
        <cline>plot!(x-&gt;opt[1]*x+opt[2],-1,10)</cline>
        </cd>
      </p>

      <p>
        resulting in
      </p>

      <figure xml:id="fig-opt-scatter2">
        <caption></caption>
        <image source="plots/optimization/scatter2.png">
          <shortdescription>
            (for accessibility)
          </shortdescription>
        </image>
      </figure>

      <p>
        and this appears to be a good fit to the data.
      </p>
    </introduction>


    <subsection>
      <title>Fitting Data to Polynomial</title>

      <p>
        As discussed elsewhere, a polynomial has many nice properties for a function.  This includes 1) there are only multiplications, additions and subtractions of numerical values to evaluate it (these are all fast operations on a CPU) and 2) horner's form of the polynomial make them super fast to evaluate. Because of this, using a polynomial as way to calculate other functions is common.
      </p>

      <p>
        In this section, we will fit a polynomial to a natural logarithm. It will be similar to fitting data to a line, except the data will be generated from a function and we will use a polynomial (of some degree as the fit).  Let's try to fit a cubic to a set of data generated by <m>y=\ln (x)</m> on <m>[1,5]</m>.  We first generate the x points with
      </p>

      <p>
        <cd>
        <cline> x=LinRange(1,5,10) </cline>
        </cd>
      </p>

      <p>
        and then can define the least squares for the log with:
      </p>

      <p>
        <cd>
        <cline>leastSqLog(c::Vector{T}) where T &lt;: Real = sum(xpt -&gt; (c[1]+c[2]*xpt+c[3]*xpt^2+c[4]*xpt^3-log(xpt))^2,x) </cline>
        </cd>
      </p>

      <p>
        and then using  Barzilai–Borwein on this:
      </p>

      <p>
        <cd>
        <cline>c = gradientDescentBB(leastSqLog,[-1,1,-1,1]) </cline>
        </cd>
      </p>

      <p>
        results in
      </p>

      <p>
        <cd>
        <cline>4-element Vector{Float64}:</cline>
        <cline> -1.0397984025249933</cline>
        <cline>  1.2746659713794941</cline>
        <cline> -0.24265284063756612</cline>
        <cline>  0.018798253240499104</cline>
        </cd>
      </p>

      <p>
        which are the 4 coefficients of the cubic polynomial.
      </p>

      <p>
        and if we plot the function with the following:
        <cd> plot([x -&gt; c[1]+c[2]*x+c[3]*x^2+c[4]*x^3,log],1,5, label=["Polynomial" "Natural Log"], legend = :topleft) </cd>
      </p>

      <p>
        which has the result
      </p>

      <figure xml:id="fig-opt-log">
        <caption></caption>
        <image source="plots/optimization/log.png">
          <shortdescription>
            (for accessibility)
          </shortdescription>
        </image>
      </figure>

      <p>
        showing that they are almost identical.  The error which is the difference between the polynomial and the log function can be plotted with:
      </p>

      <p>
        <cd> plot(x-&gt;(abs(c[1]+c[2]*x+c[3]*x^2+c[4]*x^3- log(x))),1,5) </cd>
      </p>

      <p>
        the result is
      </p>

      <figure xml:id="fig-opt-logerror">
        <caption></caption>
        <image source="plots/optimization/loge-rror.png">
          <shortdescription>
            (for accessibility)
          </shortdescription>
        </image>
      </figure>

      <p>
        and this shows that with just a cubic, we can approximate the natural log to 0.016 (almost 2 digits).  If we choose a higher-degree polynomial, we can do better and in fact, using polynomials as approximations is often the way that many mathematical functions are evaluated.
      </p>
    </subsection>
  </section>

  <section>
    <title>Using the <c>JuMP</c> package</title>

    <introduction>
      <p>
        There is a very nice package for optimization called the <c>JuMP</c> package \cite{DunningHuchetteLubin2017} which allows the ability to set up a problem, then optimize it. Make sure you add the following packages and then
      </p>

      <p>
        <cd> using JuMP, Ipopt </cd>
      </p>

      <p>
        Let's first minimize the function of two variables at the top of this chapter with
      </p>

      <p>
        <cd>
        <cline>model = Model(Ipopt.Optimizer) </cline>
        <cline>@variable(model, x, start = 0.1) </cline>
        <cline>@variable(model, y, start = 0.1) </cline>
        <cline>@NLobjective(model, Min, sin(0.5x^2-0.25y^2+2)*cos(x+y)) </cline>
        </cd>
      </p>

      <p>
        and note that there was no output.  This only adds the two variables as well as the objective function and since it is nonlinear, we use the <c>@NLobjective</c>macro.
      </p>

      <p>
        To find the minimum,
      </p>

      <p>
        <cd> optimize!(model) </cd>
      </p>

      <p>
        which returns
      </p>


      <program language="julia" line-numbers="yes">
        <input>
          ******************************************************************************
          This program contains Ipopt, a library for large-scale nonlinear optimization.
           Ipopt is released as open source code under the Eclipse Public License (EPL).
                   For more information visit https://github.com/coin-or/Ipopt
          ******************************************************************************
          This is Ipopt version 3.14.14, running with linear solver MUMPS 5.6.2.
          Number of nonzeros in equality constraint Jacobian...:        0
          Number of nonzeros in inequality constraint Jacobian.:        0
          Number of nonzeros in Lagrangian Hessian.............:        3
          Total number of variables............................:        2
                               variables with only lower bounds:        0
                          variables with lower and upper bounds:        0
                               variables with only upper bounds:        0
          Total number of equality constraints.................:        0
          Total number of inequality constraints...............:        0
                  inequality constraints with only lower bounds:        0
             inequality constraints with lower and upper bounds:        0
                  inequality constraints with only upper bounds:        0
          iter    objective    inf_pr   inf_du lg(mu)  ||d||  lg(rg) alpha_du alpha_pr  ls
             0  8.9014960e-01 0.00e+00 2.21e-01  -1.0 0.00e+00    -  0.00e+00 0.00e+00   0
             1  8.8938129e-01 0.00e+00 2.26e-01  -1.7 2.26e-03   2.0 1.00e+00 1.00e+00f  1
             2  8.8683604e-01 0.00e+00 2.40e-01  -1.7 7.19e-03   1.5 1.00e+00 1.00e+00f  1
             3  8.7635157e-01 0.00e+00 2.89e-01  -1.7 2.61e-02   1.0 1.00e+00 1.00e+00f  1
             4  7.7132679e-01 0.00e+00 5.70e-01  -1.7 1.59e-01   0.6 1.00e+00 1.00e+00f  1
             5  7.0600048e-01 0.00e+00 6.73e-01  -1.7 6.88e-02   1.0 1.00e+00 1.00e+00f  1
             6  2.3792272e-01 0.00e+00 9.03e-01  -1.7 3.57e-01   0.5 1.00e+00 1.00e+00f  1
             7 -8.1257894e-01 0.00e+00 6.74e-01  -1.7 1.13e+00   0.0 1.00e+00 1.00e+00f  1
             8 -9.5265426e-01 0.00e+00 4.47e-01  -1.7 5.61e-01    -  1.00e+00 1.00e+00f  1
             9 -9.9993858e-01 0.00e+00 1.64e-02  -1.7 2.12e-01    -  1.00e+00 1.00e+00f  1
          iter    objective    inf_pr   inf_du lg(mu)  ||d||  lg(rg) alpha_du alpha_pr  ls
            10 -1.0000000e+00 0.00e+00 9.57e-05  -3.8 7.48e-03    -  1.00e+00 1.00e+00f  1
            11 -1.0000000e+00 0.00e+00 3.43e-09  -5.7 4.25e-05    -  1.00e+00 1.00e+00f  1
          Number of Iterations....: 11
                                             (scaled)                 (unscaled)
          Objective...............:  -1.0000000000000000e+00   -1.0000000000000000e+00
          Dual infeasibility......:   3.4309616552489507e-09    3.4309616552489507e-09
          Constraint violation....:   0.0000000000000000e+00    0.0000000000000000e+00
          Variable bound violation:   0.0000000000000000e+00    0.0000000000000000e+00
          Complementarity.........:   0.0000000000000000e+00    0.0000000000000000e+00
          Overall NLP error.......:   3.4309616552489507e-09    3.4309616552489507e-09
          Number of objective function evaluations             = 12
          Number of objective gradient evaluations             = 12
          Number of equality constraint evaluations            = 0
          Number of inequality constraint evaluations          = 0
          Number of equality constraint Jacobian evaluations   = 0
          Number of inequality constraint Jacobian evaluations = 0
          Number of Lagrangian Hessian evaluations             = 11
          Total seconds in IPOPT                               = 0.032
          EXIT: Optimal Solution Found.
        </input>
      </program>

      <p>
        There's a lot to unpack here, but there just a few things to note:
      </p>

      <p>
        <ul>
          <li>
            <p>
              All of the steps are shown.  This took 11 steps and you see the objective column reports the value of the objective starting at the point <m>(0.1,0.1)</m> with value <c>8.901e-01</c>and decreasing to <c>-1.0e+00</c>
            </p>
          </li>

          <li>
            <p>
              There are total number of function, gradient, Jacobian and Hessian evaluations, where the latter two are matrices of derivatives.  Like we did in defining our gradient descent function, these are done with the <c>ForwardDiff</c>package.  This is helpful if your function takes a long time to compute to see where time is spent.
            </p>
          </li>

          <li>
            <p>
              The last line says <c>EXIT: Optimal Solution Found.</c>which is what we wanted.
            </p>
          </li>
        </ul>
      </p>

      <p>
        Note that the point itself is not listed.  We can get this with the <c>value</c>function, so
      </p>

      <p>
        <cd> value(x),value(y) </cd>
      </p>

      <p>
        returns
      </p>

      <p>
        <cd>
        <cline>(1.1036863858138652, 2.0379062691204775)</cline>
        </cd>
      </p>

      <p>
        which is the same point (to nearly the same precision) as we found above.
      </p>
    </introduction>


    <subsection>
      <title>Linear Regression with JuMP</title>

      <p>
        We can minimize this function with
      </p>

      <p>
        <cd>
        <cline>model = Model(Ipopt.Optimizer) </cline>
        <cline>set_optimizer_attribute(model,"print_level",3) </cline>
        <cline>@variable(model,m,start=0) </cline>
        <cline>@variable(model,b,start=0) </cline>
        <cline>@NLobjective(model,Min,  sum((m*pt[1]+b-pt[2])^2 for pt in pts)) </cline>
        <cline>optimize!(model) </cline>
        </cd>
      </p>

      <p>
        where we have set the <c>print_level</c>attribute of the <c>Ipopt</c> solver to 3 to print out less information. Also, note that the way the objective function is called  And we haven't shown the information here, but the most important aspect is that it found the solution. The values are
      </p>

      <p>
        <cd>
        <cline>value(m),value(b)</cline>
        </cd>
      </p>

      <p>
        which returns
      </p>

      <p>
        <cd>
        <cline>(-0.7248062015503872, 8.8953488372093)</cline>
        </cd>
      </p>

      <p>
        and now we can plot the result together with the points  with
      </p>

      <p>
        <cd>
        <cline>scatter(map(pt-&gt;pt[1],pts),map(pt-&gt;pt[2],pts),legend=false) </cline>
        <cline>plot!(x-&gt;value(m)*x+value(b),-0.5,10.5) </cline>
        </cd>
      </p>

      <p>
        resulting in
      </p>

      <figure xml:id="fig-opt-linregress">
        <caption></caption>
        <image source="plots/optimization/linregress.png">
          <shortdescription>
            (for accessibility)
          </shortdescription>
        </image>
      </figure>
      <!-- %
    </subsection>


    <subsection>
      <title>Fitting to an Exponential</title>

      % %For this section, we going to fit a dataset to an exponential curve.  First, the data found at the site  \href{https://www.esrl.noaa.gov/gmd/ccgg/trends/data.html}{https://www.esrl.noaa.gov/gmd/ccgg/trends/data.html} and look for the link to <term> Mauna Loa CO2 annual mean growth rates</term>. Click the CSV link to get a file that is easier to import. % %Also, we will using some of packages explained in Chapter \ref{ch:data}, so if needed, review that chapter.  We'll be using the following packages: %% %\begin{jlblock}[expfit] %using DataFrames, Query, CSVFiles, StatsPlots %</cd>
      %
      <cd> %using PGFPlotsX, JuMP, Ipopt %pgfplotsx() %</cd>
      %First, we need to load the data from the file.  If you open up the file, you will notice that there are many lines that start with a <c>#</c>which is meant to be a comment, but needs to be explicitly said: %\begin{jlverbatim} %CO2_data = load("co2_annmean_mlo.csv",skiplines_begin=55) |> DataFrame; %</cd>
      %
      <cd> %CO2_data = load("../common-code/co2_annmean_mlo.csv",skiplines_begin=55) |> DataFrame; %</cd>
      %and a plot of this is given with the following: %\begin{jlblock}[expfit] %@df CO2_data scatter(:year,:mean, markersize=2, legend=:topleft, label="data") %</cd>
      %\begin{center} %\pgfplotsset{scale=0.7} %\plot{plots/opt/co2scatter.tex}{expfit} %\end{center} %This plot seems to show that perhaps the function is an exponential.  We'll first try to fit to the following function: %
      <men>
        %f(t) & = C e^{kt} \label{eq:exp1} %
      </men>
      % %To make the data a bit easier to handle, we'll shift all of the years by 1959, so the variable <m>t</m> will be the number of since since 1959.  Also, to make things consistent with what we did above, we create an array of tuples (acting like points) %% %\begin{jlblock}[expfit] %co2_pts = map(i->(CO2_data[i,:year]-1959,CO2_data[i,:mean]), 1:nrow(CO2_data)) %</cd>
      %where the first 10 values are \jlc[expfit]{display(co2_pts[1:10])}\printpythontex[verbatim] % %Next, we'll set up and optimize the least squares function as: %\begin{jlblock}[expfit] %model = Model(Ipopt.Optimizer) %set_optimizer_attribute(model,"print_level",5) %@variable(model,C,start=300) %@variable(model,k,start=0.01) % %@NLobjective(model,Min,  sum((C*exp(k*pt[1])-pt[2])^2 for pt in co2_pts)) %optimize!(model) %</cd>
      %where the function in the <c>@NLobjective</c>macro is the desired function in (\ref{eq:exp1}). % %\begin{jlblock}[expfit] %value(C),value(k) %</cd>
      %
      <cd> %using Printf %display((value(C),value(k))) %</cd>
      %\printpythontex[verbatim] %\jlc[expfit]{print(@sprintf "%7.3f" value(C))} \saveprintpythontex{cval} %\jlc[expfit]{print(@sprintf "%7.5f" value(k))} \saveprintpythontex{kval} %and this means that the function fit is: %
      <me>
        %f(t) & = \useprintpythontex{cval} e^{\useprintpythontex{kval} t} %
      </me>
      %\begin{jlblock}[expfit] %plot!(t->value(C)*exp(value(k)*(t-1959)),1959,2020,label="f(t)") %</cd>
      %\begin{center} %\pgfplotsset{scale=0.7} %\plot{plots/opt/exp-overlay.tex}{expfit} %\end{center} % %Note that although the fit isn't bad, it doesn't seem like it is a great fit.  This is probably due to the function not having enough parameters to get a better fit.  If instead we try a function of the form: %
      <men>
        %g(t) = A + C e^{kt} \label{eq:exp2} %
      </men>
      %we can try fitting this with the following: %\begin{jlblock}[expfit] %model2 = Model(Ipopt.Optimizer) %set_optimizer_attribute(model2,"print_level",5) %@variable(model2,C,start=1) %@variable(model2,k,start=0.01) %@variable(model2,A,start=200) % %@NLobjective(model2,Min,  sum((A+C*exp(k*pt[1])-pt[2])^2 for pt in co2_pts)) %optimize!(model2) %</cd>
      %where we have added the extra variable <m>A</m> as well as added it to the <c>@NLobjective</c>macro. % %\begin{jlblock}[expfit] %value(C),value(k),value(A) %</cd>
      %
      <cd> %display((value(C),value(k),value(A))) %</cd>
      %\printpythontex[verbatim] %\jlc[expfit]{print(@sprintf "%6.3f" value(C))} \saveprintpythontex{cval2} %\jlc[expfit]{print(@sprintf "%7.5f" value(k))} \saveprintpythontex{kval2} %\jlc[expfit]{print(@sprintf "%7.3f" value(A))} \saveprintpythontex{aval2} %and this means that the function fit is: %
      <me>
        %g(t) & = \useprintpythontex{aval2}+\useprintpythontex{cval2} e^{\useprintpythontex{kval2} t} %
      </me>
      % %\begin{jlblock}[expfit] %plot!(t->value(A)+value(C)*exp(value(k)*(t-1959)),1959,2020,label="g(t)") %</cd>
      %\begin{center} %\pgfplotsset{scale=0.7} %\plot{plots/opt/exp-overlay2.tex}{expfit} %\end{center} %and this shows that it appears to be a pretty solid fit. -->
    </subsection>
  </section>
</chapter>
